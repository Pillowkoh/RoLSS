---
seed: 42

model:
  architecture: vit_skip
  num_classes: 530
  pretrained: true
  skip: [0,1,1, 1,1,1, 1,1,1, 1,1,1]
  mode: mlp  ### Choose one of three modes: ["all", "attention", "mlp"] ###

dataset:
  type: facescrub
  validation_set_size: 0
  image_size: 224

transformations:
  RandomResizedCrop:
    size: [224, 224]
    scale: [0.85, 1]
    ratio: [1, 1]
  ColorJitter:
    brightness: 0.2
    contrast: 0.2
    saturation: 0.1
    hue: 0.1
  RandomHorizontalFlip:
    p: 0.5

optimizer:
  Adam:
    lr: 0.001
    betas: [0.9, 0.999]
    weight_decay: 0.0

lr_scheduler:
  MultiStepLR:
    milestones: [75, 90]
    gamma: 0.1

training:
  num_epochs: 100
  batch_size: 64
  dataloader_num_workers: 8
  save_path: results/FaceScrub

rtpt:
  experiment_name: Training target classifier
  name_initials: XX

wandb:
  enable_logging: true
  args:
    project: model_inversion_targets_facescrub
    name: Vit_FaceScrub
    save_code: true

